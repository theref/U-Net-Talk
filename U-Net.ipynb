{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jamescampbell/anaconda3/envs/env_full/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Dropout, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from PIL import Image, ImageSequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Pre Processing for Training Images and Test Images\n",
    "\n",
    "def process_tif(filename):\n",
    "    \"\"\"\n",
    "    Opens a tif file, seperates out the individual images.\n",
    "    Then sets the mean to 0 and std deviation to 1\n",
    "    \"\"\"\n",
    "    tif_image = Image.open(filename)\n",
    "    images = []\n",
    "    for i, page in enumerate(ImageSequence.Iterator(tif_image)):\n",
    "        images.append(np.array(page))\n",
    "        \n",
    "    processed_images = np.array(images).astype('float32')\n",
    "    processed_images = processed_images[..., np.newaxis]\n",
    "    mean = np.mean(processed_images)  # mean for data centering\n",
    "    std = np.std(processed_images)  # std for data normalization\n",
    "\n",
    "    processed_images -= mean\n",
    "    processed_images /= std\n",
    "    return images, processed_images\n",
    "\n",
    "\n",
    "train_original, train_processed = process_tif('train-volume.tif')\n",
    "test_original, test_processed = process_tif('test-volume.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Pre Processing for Training Labels\n",
    "\n",
    "labels = Image.open('train-labels.tif')\n",
    "train_labels = []\n",
    "\n",
    "for i, page in enumerate(ImageSequence.Iterator(labels)):\n",
    "    train_labels.append(np.array(page))\n",
    "    \n",
    "train_mask = np.array(train_labels).astype('float32')\n",
    "train_mask = train_mask[..., np.newaxis]\n",
    "\n",
    "train_mask /= 255.  # scale masks to [0, 1]\n",
    "    \n",
    "train_mask[train_mask > 0.5] = 1\n",
    "train_mask[train_mask <= 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 512\n",
    "img_cols = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_unet():\n",
    "\n",
    "    inputs = Input(shape=(img_rows, img_cols, 1))\n",
    "\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu',padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu',padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2DTranspose(512, 2, strides=2, padding='same', kernel_initializer='he_normal')(drop5)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2DTranspose(256, 2, strides=2, padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2DTranspose(128, 2, strides=2, padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2DTranspose(64, 2, strides=2, padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, output=conv10)\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-4, ), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#  Train the model\n",
    "#  You don't actually need to do this, you can just load a pre-trained one below\n",
    "model = get_unet()\n",
    "model.fit(train_processed, train_mask, batch_size=1, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Save the model so we don't have to keep training\n",
    "model.save('saved-unet-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Load a pretrained model\n",
    "from keras.models import load_model\n",
    "model = load_model('saved-unet-model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 477s 16s/step\n"
     ]
    }
   ],
   "source": [
    "#  Create Predictions for the training images\n",
    "results = model.predict(train_processed, batch_size=1, verbose=1)\n",
    "results = np.squeeze(results)\n",
    "results[results > 0.5] = 1\n",
    "results[results <= 0.5] = 0\n",
    "results *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  Compare the original training image, the labelled image and the predicted label\n",
    "y = 7\n",
    "Image.fromarray(results[y]).show()\n",
    "Image.fromarray(train_original[y]).show()\n",
    "Image.fromarray(train_labels[y]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 388s 13s/step\n"
     ]
    }
   ],
   "source": [
    "#  Create predictions for the test images\n",
    "testing = model.predict(test_processed, batch_size=1, verbose=1)\n",
    "testing = np.squeeze(testing)\n",
    "testing[testing > 0.5] = 1\n",
    "testing[testing <= 0.5] = 0\n",
    "testing *= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compare the original test image with the predicted label\n",
    "x = 10\n",
    "Image.fromarray(testing[x]).show()\n",
    "Image.fromarray(test_original[x]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
